
현재 짜여진 코드는 단순히 `reuqest`를 보내서 받은 다음에 크롤링하는 로직임
이런 로직은 `reddit`에서 권장하지 않은 방식. 애초에 `reddit`에서 `api`를 공식적으로 지원해줌
그래서 현재 로직을 api를 이용하여 크롤링하는것으로 대체함 → **구현 완료**

Oauth 토큰을 발급받아 사용하기 위한 기본 정보는 `.env`파일에 저장되어있음
`Oauth`로 발급 받은 토큰은 약 1시간정도만 유효하니 갱신 로직을 추가해야함 → **토큰 캐시 및 자동 갱신 구현**

현재 api를 이용해서 얻어야하는 정보는 다음과 같음
1. 게시글의 제목
2. 게시글 원문 URL
3. 게시글 작성자
4. 게시글 본문 (없을 시 공백)
5. 게시글 작성 시간
6. api를 사용하여 해당 답변을 받은 시점(크롤링 시행한 시간)
7. 업보트 수
8. 댓글 수
9. /r/.../ 형태의 Reddit 내부 링크
10. 텍스트 게시물 여부
11. 게시글에 붙은 플레어
12. 게시글에 달린 댓글 (상위 50개, 깊이 2 단계까지)


해당 api를 이용해서 기존 디시인사이드처럼 게시글 크롤링해서 item에 저장하고, codex를 이용하여 요약하고, 요약할 수 있게끔 하고 싶음


# 요구사항
1. 기존 `Request`방식의 크롤링방식을 `Reddit`의 공식 `api`를 이용하여 구현 → `crawl_reddit.py` 전면 교체 완료
   - 스크립트 앱 자격증명(`.env`)을 읽어 OAuth 토큰 발급
   - 토큰 만료 시 자동 재발급, 401 응답에도 재시도
   - `https://oauth.reddit.com` 경유로 게시글/댓글 수집
   - 게시글 메타데이터에 `fetched_at`, `comments` 등 추가 저장
2. 해당 `Oauth`의 토큰은 약 1시간 후 사라지니 갱신/재발급 받는 로직 필요
3. 
